Dilemmas~Environmental studies~Moral psychology~Non-cooperative games~Social psychology~Social science experiments~Thought experiments~
||||||
Prisoner's dilemma
||||||
The Prisoner's Dilemma is an example of a game analyzed in game theory. It is also a thought experiment that challenges two completely rational agents to a dilemma: cooperate with their partner for mutual reward, or betray their partner ("defect") for individual reward.

This dilemma was originally framed by Merrill Flood and Melvin Dresher while working at RAND in 1950. Albert W. Tucker appropriated the game and formalized it by structuring the rewards in terms of prison sentences and named it "prisoner's dilemma".  William Poundstone in his 1993 book Prisoner's Dilemma writes the following version:Two members of a criminal gang are arrested and imprisoned. Each prisoner is in solitary confinement with no means of speaking to or exchanging messages with the other. The police admit they don't have enough evidence to convict the pair on the principal charge. They plan to sentence both to a year in prison on a lesser charge. Simultaneously, the police offer each prisoner a Faustian bargain.The possible outcomes are:
A: If A and B each betray the other, each of them serves 5 years in prison
B: If A betrays B but B remains silent, A will be set free and B will serve 10 years in prison
C: If A remains silent but B betrays A, A will serve 10 years in prison and B will be set free
D: If A and B both remain silent, both of them will serve 2 years in prison (on the lesser charge).As a projection of rational behaviour in terms of loyalty to one's partner in crime, the Prisoner's Dilemma suggests that criminals who are offered a greater reward will betray their partner for the reward. 
Accepting offers such as B shows that loyalty to one's partner is, in this game, irrational. Rationality in a system that profits from others, governs this behaviour.  Alternative ideas governing behaviour have been proposed, see for example, Elinor Ostrom a Nobel Laureate in Economics. 
An assumption of the Prisoner's Dilemma is that all purely rational behaviour is self-interested, and as such people will betray each other for self-interest. This implies the only possible outcome for two purely rational prisoners is for them to betray each other, even though mutual cooperation would yield a greater reward.In this case, "to betray" is the dominant strategy for both players, meaning it is the player's best response in all circumstances, and it is aligned with the sure-thing principle. The prisoner's dilemma also illustrates that the decisions made under collective rationality may not necessarily be the same as those made under individual rationality, and this conflict can also be witnessed in a situation called the "Tragedy of the Commons". This case indicates the fact that public goods are always prone to over-use.In reality, such systemic bias towards cooperative behavior happens despite what is predicted by simple models of "rational" self-interested action. This bias towards cooperation has been known since the test was first conducted at RAND; the secretaries involved trusted each other and worked together for the best common outcome. The prisoner's dilemma became the focus of extensive experimental research. This experimental research usually takes one of three forms: single play, iterated play and iterated play against a programmed player, each with different purposes. And as a summary of these experiments, their results justify the categorical imperative raised by Immanuel Kant, which states that a rational agent is expected to "act in the way you wish others to act." This theory is vital for a situation when there are different players each acting for their best interest, and has to take others' actions into consideration to form their own choice. It underlines the interconnectedness of players in such a game, thus stressing the fact that a strategy has to consider others' reactions to be successful, including their responsiveness, their tendency to imitate, etc.An extended "iterated" version of the game also exists. In this version, the classic game is played repeatedly between the same prisoners, who continuously have the opportunity to penalize the other for previous decisions. If the number of times the game will be played is known to the players, then by backward induction two classically rational players will betray each other repeatedly, for the same reasons as the single-shot variant. In an infinite or unknown length game there is no fixed optimum strategy, and prisoner's dilemma tournaments have been held to compete and test algorithms for such cases.The iterated version of the prisoner's dilemma is of particular interest to researchers. Due to its iterative nature, previous researchers observed that the frequency for players to cooperate could change, based on the outcomes of each iteration. Specifically, a player may be less willing to cooperate if their counterpart did not cooperate many times, which renders disappointment. Conversely, as time goes by, cooperation could increase, mainly attributable to the fact that a "tacit agreement" between players has been set up. Another interesting aspect concerning the iterated version of experiment, however, is that this tacit agreement between players has always been established successfully even though the number of iterations is made public to both sides.The prisoner's dilemma game can be used as a model for many real world situations involving cooperative behavior. In casual usage, the label "prisoner's dilemma" may be applied to situations not strictly matching the formal criteria of the classic or iterative games: for instance, those in which two entities could gain important benefits from cooperating or suffer from the failure to do so, but find it difficult or expensive—not necessarily impossible—to coordinate their activities.